ğŸ“š Talk2Books â€” Multilingual RAG App

ğŸ¤– Ask questions from your uploaded books or documents â€” in English, Hindi, or Punjabi â€” and get AI-powered answers in any of these languages!

Talk2Books is a Retrieval-Augmented Generation (RAG) system built with LangChain, FAISS, and Ollama.
It uses local embeddings, language detection, and translation to understand and answer questions from uploaded text files â€” no external APIs required.

âœ¨ Features

âœ… Upload up to 5 text/PDF/DOCX files
âœ… Multi-language support â€” English, Hindi, Punjabi
âœ… Choose question and answer language independently
âœ… Automatic language detection and translation
âœ… Local inference using Ollama models (e.g., qwen2.5:3b)
âœ… Stores uploaded files temporarily â€” deleted after session
âœ… Modern, clean frontend UI built with HTML/CSS/JS
âœ… Backend powered by Quart (async Flask) and LangChain

ğŸ—ï¸ Tech Stack
Component	Technology
Frontend	HTML, CSS, Vanilla JavaScript
Backend	Python, Quart, Quart-CORS
AI/RAG Framework	LangChain Core + Community + FAISS
Embeddings	Sentence Transformers (all-MiniLM-L6-v2)
LLM	Ollama (qwen2.5:3b)
Language Translation	Deep Translator
Vector Store	FAISS (local)
Environment	Python 3.10+
ğŸ“‚ Project Structure
talk2books/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                   # Main Quart server
â”‚   â”œâ”€â”€ rag_chain.py             # RAG + translation logic
â”‚   â”œâ”€â”€ loaders.py               # Document loading & splitting
â”‚   â”œâ”€â”€ requirements.txt         # Dependencies
â”‚   â”œâ”€â”€ run_backend.bat          # Windows start script
â”‚   â”œâ”€â”€ run_backend.sh           # Linux/Mac start script
â”‚   â”œâ”€â”€ sample_docs/             # Uploaded files stored temporarily
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html               # UI for upload and Q&A
    â”œâ”€â”€ script.js                # Frontend logic (upload + ask)
    â””â”€â”€ style.css                # UI styling

âš™ï¸ Setup Instructions
ğŸ§© Prerequisites

Python 3.10 or newer

(Optional) Ollama
 installed with model qwen2.5:3b

ollama pull qwen2.5:3b


Git (for cloning)

ğŸª„ 1. Clone the Repository
git clone https://github.com/<your-username>/talk2books.git
cd talk2books/backend

ğŸ§± 2. Create a Virtual Environment
Windows:
python -m venv .venv
.venv\Scripts\activate

macOS/Linux:
python3 -m venv .venv
source .venv/bin/activate

ğŸ“¦ 3. Install Dependencies
pip install --upgrade pip
pip install -r requirements.txt

â–¶ï¸ 4. Run the Backend
python app.py


If successful, youâ€™ll see:

ğŸš€ Starting Talk2Books backend (multi-language, temp session mode)...
 * Running on http://0.0.0.0:5000

ğŸŒ 5. Launch the Frontend

Open the file manually:

talk2books/frontend/index.html


Or run a local server:

cd ../frontend
python -m http.server 5500


Then visit â†’ http://localhost:5500

ğŸ§  How It Works

Upload up to 5 files (any combination of .txt, .pdf, .docx).

The system detects their language using langdetect.

Texts are split into chunks and embedded via sentence-transformers.

FAISS builds a vector index for fast retrieval.

When you ask a question:

The question language is auto-detected.

It is translated to English for consistent retrieval.

The top chunks are fetched via FAISS.

Ollamaâ€™s qwen2.5:3b generates an answer.

The final answer is translated back into your selected answer language.

ğŸ§¾ Example Use
Input	Output
Question (Hindi): à¤…à¤°à¥à¤œà¥à¤¨ à¤•à¥Œà¤¨ à¤¥à¤¾?
Answer Language: English	â€œArjuna was one of the Pandava brothers in the Mahabharata...â€
Question (English): Who is Guru Nanak Dev Ji?
Answer Language: Punjabi	â€œà¨—à©à¨°à©‚ à¨¨à¨¾à¨¨à¨• à¨¦à©‡à¨µ à¨œà©€ à¨¸à¨¿à©±à¨– à¨§à¨°à¨® à¨¦à©‡ à¨¸à©°à¨¸à¨¥à¨¾à¨ªà¨• à¨¸à¨¨â€¦â€
ğŸ’» Run Scripts (Optional)
Windows (auto setup)

Double-click run_backend.bat

macOS/Linux
chmod +x run_backend.sh
./run_backend.sh

ğŸ§¹ Cleanup & Session Handling

Uploaded files are stored temporarily in backend/sample_docs/

On server restart or after session ends â†’ all uploads are deleted automatically.

ğŸš€ Deployment Options
ğŸ§© Local Environment

Use Python venv as shown above.

ğŸ³ Docker (Optional)

Add this Dockerfile inside /backend:

FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 5000
CMD ["python", "app.py"]


Then build & run:

docker build -t talk2books .
docker run -p 5000:5000 talk2books

ğŸ§° Troubleshooting
Problem	Fix
ModuleNotFoundError: No module named 'langchain.text_splitter'	Run pip install -U langchain-text-splitters
FAISS list index out of range	Make sure at least one valid document is uploaded
LLM not found (Ollama)	Run ollama pull qwen2.5:3b before starting backend
Answer not in target language	Ensure deep-translator is installed and working properly
Network error in browser	Backend must run at localhost:5000; check CORS in app.py
ğŸ“œ License

This project is open-source under the MIT License â€” free to use, modify, and share.

ğŸ‘©â€ğŸ’» Author

Developed by Sanya
ğŸ’¬ Inspired by the idea of bridging language diversity with AI.

If you like this project, give it a â­ on GitHub
 and share it with others!
